# AI-Powered File Processing - Setup & Testing Guide

## ğŸš€ QUICK START

### Step 1: Install Python Dependencies

```bash
cd python-api
pip install -r requirements.txt
```

This will install:
- `anthropic==0.39.0` - Claude AI SDK
- `pandas==2.2.3` - Data processing
- `numpy==2.1.3` - Numerical operations
- `openpyxl==3.1.5` - Excel file support
- `python-dateutil==2.9.0` - Date parsing

### Step 2: Set Up Anthropic API Key

1. **Get your API key** from: https://console.anthropic.com/settings/keys
   - Sign up if you don't have an account
   - Create a new API key
   - Copy the key (starts with `sk-ant-api03-...`)

2. **Create `.env` file** in `python-api/` directory:
   ```bash
   # In python-api/ directory
   echo ANTHROPIC_API_KEY=sk-ant-api03-YOUR-ACTUAL-KEY-HERE > .env
   ```

3. **Verify** the file:
   ```bash
   type .env   # Windows
   cat .env    # Mac/Linux
   ```

### Step 3: Test the Python API

```bash
# Start the Python API server
cd python-api
python main.py
```

You should see:
```
INFO:     Uvicorn running on http://127.0.0.1:8000
INFO:     Application startup complete.
```

### Step 4: Test Health Check

Open another terminal:

```bash
# Check if API is running
curl http://localhost:8000/health
```

Should return:
```json
{
  "status": "healthy",
  "message": "Python API is running!",
  "anthropic_configured": true  â† MUST BE TRUE
}
```

If `anthropic_configured` is `false`:
- Check `.env` file exists
- Check API key format
- Restart Python server

---

## ğŸ§ª TESTING FILE PROCESSING

### Test 1: Upload via Frontend (Recommended)

1. **Start all servers**:
   ```bash
   # In Website/ root directory
   npm run dev
   ```
   This starts: Vite (3000), Express (3001), Python (8000)

2. **Navigate to Sources page**:
   - Go to: http://localhost:5173
   - Login/Register
   - Click "Sources" in navigation
   - Click "Upload Files"

3. **Upload test CSV**:
   - Use `python-api/test_sample_data.csv`
   - Watch the progress bar
   - Wait for "Completed" status
   - Click on the file to see subsets

### Test 2: Direct API Test (Advanced)

```bash
# Test with curl (replace with your base64 encoded file)
curl -X POST http://localhost:8000/api/process-file \
  -H "Content-Type: application/json" \
  -d '{
    "fileBuffer": "BASE64_ENCODED_FILE_CONTENT",
    "fileName": "test.csv",
    "fileType": "text/csv"
  }'
```

Or use Python script:

```python
import requests
import base64

# Read file
with open('test_sample_data.csv', 'rb') as f:
    file_bytes = f.read()

# Encode to base64
file_b64 = base64.b64encode(file_bytes).decode('utf-8')

# Send to API
response = requests.post('http://localhost:8000/api/process-file', json={
    'fileBuffer': file_b64,
    'fileName': 'test.csv',
    'fileType': 'text/csv'
})

print(response.json())
```

---

## ğŸ“Š WHAT TO EXPECT

### Successful Processing

Claude AI will analyze your file and return:

1. **File Schema**:
   ```json
   {
     "columns": [
       {"name": "date", "type": "date", "description": "Transaction date"},
       {"name": "sales", "type": "number", "description": "Sales amount"}
     ],
     "rowCount": 50,
     "summary": "Sales data from Jan-Mar 2024..."
   }
   ```

2. **Multiple Subsets** (5-15 visualizations):
   - Time series trends
   - Category comparisons
   - Distribution charts
   - Correlations
   - Aggregated views

### Example Subsets Generated

For the test CSV file, Claude might generate:

1. **"Daily Sales Trend"** - Line chart showing sales over time
2. **"Sales by Category"** - Bar chart comparing product categories
3. **"Monthly Total Revenue"** - Area chart of cumulative sales
4. **"Top Products by Revenue"** - Bar chart of best sellers
5. **"Sales by Region"** - Pie chart of regional distribution
6. **"Customer Type Analysis"** - Bar chart comparing B2B vs Consumer
7. **"Units Sold by Product"** - Bar chart of quantity sold
8. **"Weekly Sales Pattern"** - Line chart showing day-of-week trends
9. **"Product Category Distribution"** - Pie chart of category mix
10. **"Average Sale Value by Region"** - Bar chart of regional averages

---

## ğŸ› TROUBLESHOOTING

### Issue 1: `anthropic_configured: false`

**Cause**: API key not found or invalid

**Fix**:
```bash
# Check .env file
cd python-api
type .env  # Windows
cat .env   # Mac/Linux

# Should show:
# ANTHROPIC_API_KEY=sk-ant-api03-...

# If missing, create it:
echo ANTHROPIC_API_KEY=your-key-here > .env

# Restart Python server
python main.py
```

### Issue 2: `ModuleNotFoundError: No module named 'pandas'`

**Cause**: Dependencies not installed

**Fix**:
```bash
cd python-api
pip install -r requirements.txt
```

### Issue 3: Processing Fails with "Invalid JSON"

**Cause**: Claude sometimes wraps JSON in markdown

**Fix**: Already handled in code! The function strips markdown code blocks.

If it still fails, check Python terminal for error details.

### Issue 4: "No subsets generated by Claude"

**Cause**: File might be too small, empty, or malformed

**Fix**:
1. Check file has data (at least 5 rows)
2. Check CSV has headers
3. Look at Python logs for Claude's actual response
4. Try with test_sample_data.csv

### Issue 5: Processing Takes Too Long (>30 seconds)

**Cause**: Large file or Claude API delay

**Fix**:
- For files >5000 rows, code samples 1000 rows
- Check internet connection
- Check Anthropic API status: https://status.anthropic.com/

### Issue 6: API Rate Limit Error

**Cause**: Too many requests to Claude API

**Fix**:
- Wait 1 minute between uploads
- Check your Anthropic API usage limits
- Free tier has rate limits

---

## ğŸ” DEBUGGING TIPS

### Enable Verbose Logging

In `main.py`, the function already prints:
- "ğŸ“Š Sending data to Claude..."
- "âœ… Claude response received"
- "âœ¨ Successfully generated X subsets"
- "âŒ Error messages"

Watch the Python terminal while processing files!

### Check Claude's Raw Response

If processing fails, check Python logs for:
```
Response text: {...}
```

This shows what Claude actually returned.

### Test with Simple Data First

Use the provided `test_sample_data.csv`:
- Small (50 rows)
- Clean data
- Multiple data types
- Time series included

---

## ğŸ“ˆ PERFORMANCE METRICS

### Expected Processing Times

| File Size | Rows | Processing Time |
|-----------|------|-----------------|
| Small | <100 | 5-10 seconds |
| Medium | 100-1000 | 10-15 seconds |
| Large | 1000-5000 | 15-25 seconds |
| Very Large | >5000 | 20-30 seconds |

*Note: Uses sampling for >5000 rows*

### Token Usage (Anthropic)

Approximate token counts:
- System prompt: ~500 tokens
- Data (100 rows): ~2000 tokens
- Claude response: ~3000-8000 tokens
- **Total per file**: ~5000-10000 tokens

**Cost Estimate** (Claude Sonnet 4):
- ~$0.003 per file processed (input)
- ~$0.012 per file processed (output)
- **~$0.015 total per file**

---

## âœ… SUCCESS CHECKLIST

Before reporting issues, verify:

- [ ] Python dependencies installed (`pip list | grep pandas`)
- [ ] `.env` file exists with valid API key
- [ ] Python server running (`http://localhost:8000/health`)
- [ ] Health check shows `"anthropic_configured": true`
- [ ] Express API running (`http://localhost:3001/health`)
- [ ] Frontend running (`http://localhost:5173`)
- [ ] Test CSV file has data and headers
- [ ] No errors in Python terminal
- [ ] No errors in Express terminal
- [ ] No errors in browser console

---

## ğŸ¯ WHAT CLAUDE DOES

1. **Receives**: Your complete dataset (or sample if large)
2. **Analyzes**:
   - Column types (numbers, dates, categories)
   - Data patterns (trends, distributions)
   - Relationships between columns
   - Temporal patterns (if dates present)
3. **Generates**:
   - Intelligent subsets optimized for different chart types
   - Aggregations (daily/monthly/category totals)
   - Comparisons (category breakdowns)
   - Trends (time series)
   - Distributions (histograms, pie charts)
4. **Returns**: 5-15 visualization-ready subsets with:
   - Clear descriptions
   - Axis labels and descriptions
   - Formatted data points

---

## ğŸ”§ ADVANCED CONFIGURATION

### Adjust Number of Subsets

Edit `main.py` system prompt:
```python
# Change "5-15 diverse" to "10-20 diverse" for more subsets
system_prompt = f"""...create 10-20 diverse, meaningful visualization subsets."""
```

### Adjust Sample Size for Large Files

Edit `main.py`:
```python
MAX_ROWS = 5000  # Increase to send more data to Claude
sample_df = df.sample(n=min(1000, row_count))  # Increase sample size
```

### Change Claude Model

Edit `main.py`:
```python
model="claude-sonnet-4-20250514",  # or "claude-opus-4-..."
max_tokens=16000,  # Increase for longer responses
temperature=0.3,  # Lower for more consistent output
```

---

## ğŸ“ SUPPORT

If you encounter issues:

1. **Check Python logs** - Most errors show here
2. **Check browser console** - Frontend errors
3. **Test with sample CSV** - Isolate file issues
4. **Verify API key** - Most common issue
5. **Check Anthropic status** - https://status.anthropic.com/

---

## ğŸ‰ NEXT STEPS

Once file processing works:

1. Upload more complex datasets
2. Test with Excel files (.xlsx)
3. Test with large files (>1000 rows)
4. Experiment with different data types
5. Share interesting visualizations!

---

*Happy Data Analyzing! ğŸ“Šâœ¨*
